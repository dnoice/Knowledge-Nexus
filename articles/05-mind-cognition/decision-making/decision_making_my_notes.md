<!--
✒ Metadata
    - Title: Decision Making Personal Notes (Knowledge Nexus 2026 Edition - v1.0)
    - File Name: decision_making_my_notes.md
    - Relative Path: articles\05-mind-cognition\decision-making\decision_making_my_notes.md
    - Artifact Type: docs
    - Version: 1.0.0
    - Date: 2026-01-03
    - Update: Friday, January 03, 2026
    - Author: Dennis 'dnoice' Smaltz
    - A.I. Acknowledgement: Google Deep Mind - Gemini 3 Pro
    - Signature: ︻デ═─── ✦ ✦ ✦ | Aim Twice, Shoot Once!

✒ Description:
    Personal analysis of decision-making science—what prospect theory revealed,
    what the neural findings mean, and where reason meets its limits.

✒ Key Features:
    - Feature 1: Theoretical assessment
    - Feature 2: Practical implications
    - Feature 3: The rationality question
    - Feature 4: Personal framework

✒ Usage Instructions:
    Personal reference. Companion to decision_making.md.

✒ Other Important Information:
    - Perspective: Applied cognitive analysis
---------
-->

# Decision Making: Personal Notes

## The Core Insight

Kahneman and Tversky's work demolished the rational actor model—the idea that humans are calculating machines optimizing expected utility. We're not. We're heuristic machines that work well enough in ancestral environments but break predictably in modern ones.

This isn't pessimistic. It's liberating. Once you know the biases, you can design around them.

## System 1 and System 2 in Practice

The dual-process model is more than academic taxonomy. It describes lived experience:

**System 1 dominates more than we realize:**
- Most "decisions" are automatic responses
- Conscious deliberation is effortful and rare
- We confabulate reasons after System 1 has already chosen

**System 2 is weaker than we think:**
- Limited by working memory capacity
- Depleted by cognitive load
- Often just rationalizes System 1 choices

The implication: willpower and "thinking harder" aren't reliable solutions. Environmental design—choice architecture—works better than exhortation.

## The Loss Aversion Number

λ ≈ 2.25

This single coefficient explains vast swaths of human behavior:

- Why people hold losing investments too long (selling crystallizes the loss)
- Why insurance purchases spike after disasters (even when risks haven't changed)
- Why negotiators fixate on concessions (losses loom larger than equivalent gains)
- Why the endowment effect exists (giving up feels like losing)

The 2025 insurance data makes this visceral: 58% surge in health insurance during COVID despite only 0.3% severe illness probability. The potential loss—death, disability—dominated the probability calculation.

## What Phineas Gage Teaches

Gage's case is cited constantly, but the implications are underappreciated:

1. **Emotion is not opposed to reason—it's essential to it.** Without emotional valuation (vmPFC function), even basic decisions become impossible.

2. **Abstract reasoning isn't enough.** Gage could still reason logically. He couldn't translate reasoning into appropriate action.

3. **The body matters.** Somatic markers—gut feelings—are information, not noise.

This connects to embodied cognition: the mind isn't just in the brain, and rationality isn't just computation.

## The Heuristics Debate: Both Sides Are Right

Kahneman emphasizes bias. Gigerenzer emphasizes ecological rationality. The resolution:

**Context determines whether heuristics help or hurt.**

- Availability heuristic in a small tribe (where you've seen everything relevant) = adaptive
- Availability heuristic with media exposure (vivid rare events overrepresented) = distorting

The lesson isn't that heuristics are bad. It's that modern environments often violate the assumptions under which heuristics evolved.

## Key Numbers

| Metric | Value |
| ------ | ----- |
| Loss aversion coefficient (λ) | ~2.25 |
| System 2 capacity | ~4 chunks |
| Overconfidence: 90% intervals contain truth | ~50% |
| Anchoring adjustment insufficiency | ~50% |
| Time to ignition (threshold for conscious deliberation) | ~300 ms |

## What I'm Taking Away

**1. Design the environment, not the person.**

Nudges work better than education. Defaults matter more than intentions. Make the right choice easy.

**2. Distrust intuitive confidence.**

Feeling certain doesn't mean being right. Calibrate by tracking predictions over time.

**3. Use pre-commitment.**

Bind yourself before the moment of temptation. Ulysses tied himself to the mast because he knew he'd fail if he relied on willpower.

**4. Respect the body's input.**

Gut feelings aren't irrational—they're data from a different system. The question is which system to trust in which context.

**5. Study your own biases.**

Everyone thinks they're less biased than average. This is itself a bias. Humility is the meta-correction.

## The Rationality Answer

Are we rational? The nuanced answer:

- **Normatively**: No. We violate logic, probability, consistency.
- **Ecologically**: Often yes. Heuristics work in appropriate contexts.
- **Instrumentally**: Sometimes. We can improve with training and design.

We're not rational. We're not irrational. We're *boundedly* rational—doing well enough given constraints, with systematic blind spots.

The goal isn't to become perfectly rational (impossible). It's to know where you'll fail and design accordingly.

## Connections to Other Topics

- **Consciousness theories**: What role does conscious deliberation (System 2) actually play?
- **Embodied cognition**: Somatic markers suggest decision-making is distributed, not just cortical
- **Collective intelligence**: Groups can correct individual biases—or amplify them
- **Artificial minds**: AI systems don't share human biases but have their own failure modes

## Open Questions

1. Can AI systems help debias human decisions without creating new dependencies?
2. Is loss aversion culturally universal or partially learned?
3. How does System 1/2 balance change across the lifespan?
4. Can nudges scale to societal-level problems (climate, health)?
5. What are the ethics of choice architecture at scale?

## Bottom Line

Decision-making research reveals we're not the rational agents we imagine ourselves to be. But we're not helpless either. Understanding the architecture of choice—how we actually decide, not how we think we decide—enables designing better outcomes.

The insight isn't that humans are irrational. It's that rationality is achievable through systems, not just individuals.

---

> **︻デ═─── ✦ ✦ ✦ | Aim Twice, Shoot Once!**
